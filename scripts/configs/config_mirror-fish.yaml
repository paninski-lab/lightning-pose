data:
  # resize dimensions to streamline model creation
  image_resize_dims:
    height: 256
    width: 384
  # ABSOLUTE path to data directory
  data_dir: /home/zeus/content/data/mirror-fish
  # ABSOLUTE path to unlabeled videos' directory
  video_dir: /home/zeus/content/data/mirror-fish/videos
  # location of labels; for example script, this should be relative to `data_dir`
  csv_file: "CollectedData.csv"
  # total number of body parts
  num_keypoints: 51
  keypoint_names:
    - chin_tip_main
    - chin3_4_main
    - chin_half_main
    - chin1_4_main
    - chin_base_main
    - head_main
    - mid_main
    - tail_neck_main
    - caudal_v_main
    - caudal_d_main
    - pectoral_L_base_main
    - pectoral_L_main
    - pectoral_R_base_main
    - pectoral_R_main
    - dorsal_main
    - anal_main
    - fork_main
    - chin_tip_top
    - chin3_4_top
    - chin_half_top
    - chin1_4_top
    - chin_base_top
    - head_top
    - mid_top
    - tail_neck_top
    - caudal_v_top
    - caudal_d_top
    - pectoral_L_base_top
    - pectoral_L_top
    - pectoral_R_base_top
    - pectoral_R_top
    - dorsal_top
    - anal_top
    - fork_top
    - chin_tip_right
    - chin3_4_right
    - chin_half_right
    - chin1_4_right
    - chin_base_right
    - head_right
    - mid_right
    - tail_neck_right
    - caudal_v_right
    - caudal_d_right
    - pectoral_L_base_right
    - pectoral_L_right
    - pectoral_R_base_right
    - pectoral_R_right
    - dorsal_right
    - anal_right
    - fork_right
  # for mirrored setups with all keypoints defined in same csv file, define matching
  # columns for different keypoints (assumes x-y-x-y interleaving)
  # each list corresponds to a single view, so in the example below there are 2 views
  # keypoint 0 is from view 0 and matches up with keypoint 8 from view 2
  # columns that correspond to keypoints only labeled in a single view are omitted
  # TODO: what if a keypoint is labeled in more than 1 but not all views?
  # this info is only used for the multiview pca loss
  mirrored_column_matches:
    - [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
    - [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]
    - [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]
  # all labels in multiple views w/ <40 nans
  columns_for_singleview_pca:
    [4, 5, 6, 7, 8, 9, 14, 15, 16, 22, 23, 24, 38, 39, 40, 41, 42, 43, 48, 50]

training:
  # select from one of several predefined image/video augmentation pipelines
  # default- resizing only
  # dlc- imgaug pipeline implemented in DLC 2.0 package
  # dlc-top-down- dlc augmentations plus vertical and horizontal flips
  imgaug: dlc
  # batch size of labeled data during training
  train_batch_size: 8
  # batch size of labeled data during validation
  val_batch_size: 48
  # batch size of labeled data during test
  test_batch_size: 48
  # fraction of labeled data used for training
  train_prob: 0.95
  # fraction of labeled data used for validation (remaining used for test)
  val_prob: 0.05
  # <=1 - fraction of total train frames (determined by `train_prob`) used for training
  # >1 - number of total train frames used for training
  train_frames: 1
  # number of gpus to train a single model
  num_gpus: 1
  # epochs over which to assess validation metrics for early stopping
  early_stop_patience: 3
  # epoch at which backbone network weights begin updating
  unfreezing_epoch: 20
  # max training epochs; training may exit before due to early stopping
  min_epochs: 500
  max_epochs: 500
  # frequency to log training metrics (one step is one batch)
  log_every_n_steps: 10
  # frequency to log validation metrics
  check_val_every_n_epoch: 5
  # rng seed for labeled batches
  rng_seed_data_pt: 0
  # rng seed for weight initialization
  rng_seed_model_pt: 0
  # learning rate scheduler
  # multisteplr | [todo - reducelronplateau]
  lr_scheduler: multisteplr
  lr_scheduler_params:
    multisteplr:
      milestones: [150, 200, 250]
      gamma: 0.5

model:
  # list of unsupervised losses
  losses_to_use: []
  # backbone network
  backbone: resnet50  # DO NOT USE resnet50_animal_ap10k
  # prediction mode: regression | heatmap | heatmap_mhcrnn (context)
  model_type: heatmap
  # which heatmap loss to use
  heatmap_loss_type: mse
  # tt expt name
  model_name: rebuttal23a

dali:
  base:
    train:
      sequence_length: 16 # step = sequence_length by default. done internally
    predict:
      # (train_batch_size + base.train.sequence_length) * 2 -> round down to nearest pow of 2
      sequence_length: 64 # step = sequence_length by default. done internally.
  context:
    train: # defaults: sequence_length=5, step=sequence_length
      batch_size: 8
    predict: # defaults: sequence_length=5, step=1
      sequence_length: 64

losses:
  # loss = projection onto the discarded eigenvectors
  pca_multiview:
    # weight in front of PCA loss
    log_weight: 5.0
    # predictions should lie within the low-d subspace spanned by these components
    components_to_keep: 3
    # absolute error (in pixels) below which pca loss is zeroed out; if null, an empirical
    # epsilon is computed using the labeled data
    epsilon: null
  # loss = projection onto the discarded eigenvectors
  pca_singleview:
    # weight in front of PCA loss
    log_weight: 5.0
    # predictions should lie within the low-d subspace spanned by components that describe this fraction of variance
    components_to_keep: 0.99
    # absolute error (in pixels) below which pca loss is zeroed out; if null, an empirical
    # epsilon is computed using the labeled data
    epsilon: null
  # loss = norm of distance between successive timepoints
  temporal:
    # weight in front of temporal loss
    log_weight: 5.0
    # for epsilon insensitive rectification
    # (in pixels; diffs below this are not penalized)
    epsilon: 10.0
    # nan removal value.
    # (in prob; heatmaps with max prob values are removed)
    prob_threshold: 0.05

eval:
  # paths to the hydra config files in the output folder, OR absolute paths to such folders.
  hydra_paths: [" "]
  # predict?
  predict_vids_after_training: true
  # save .mp4?
  save_vids_after_training: false
  fiftyone:
    # will be the name of the dataset (Mongo DB) created by FiftyOne. for video dataset, we will append dataset_name + "_video"
    dataset_name: mirror-fish
    # if you want to manually provide a different model name to be displayed in FiftyOne
    model_display_names: ["test_model"]
    # whether to launch the app from the script (True), or from ipython (and have finer control over the outputs)
    launch_app_from_script: false

    remote: True # for LAI, must be False
    address: 127.0.0.1 # ip to launch the app on.
    port: 5151 # port to launch the app on.

  # str with an absolute path to a directory containing videos for prediction.
  test_videos_directory: /home/zeus/content/data/mirror-fish/videos_new
  # confidence threshold for plotting a vid
  confidence_thresh_for_vid: 0.9

callbacks:
  anneal_weight:
    attr_name: total_unsupervised_importance
    init_val: 0.0
    increase_factor: 0.01
    final_val: 1.0
    freeze_until_epoch: 0
