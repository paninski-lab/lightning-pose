data:
  # dimensions of training images
  image_orig_dims:
    width: 1056
    height: 1024

  # resize dimensions to streamline model creation
  image_resize_dims:
    width: 384
    height: 384

  # ABSOLUTE path to data directory
  data_dir: "/datastores/fish_implant"
  # ABSOLUTE path to unlabeled videos' directory
  video_dir: "/datastores/fish_implant/videos"
  # location of labels; for example script, this should be relative to `data_dir`
  csv_file: "master_multicam_labeledFrames.csv"
  # downsample heatmaps - 2 | 3
  downsample_factor: 2
  # total number of body parts
  num_keypoints: 76
  # for mirrored setups with all keypoints defined in same csv file, define matching
  # columns for different keypoints (assumes x-y-x-y interleaving)
  # each list corresponds to a single view, so in the example below there are 2 views
  # keypoint 0 is from view 0 and matches up with keypoint 8 from view 2
  # columns that correspond to keypoints only labeled in a single view are omitted
  # TODO: what if a keypoint is labeled in more than 1 but not all views?
  # this info is only used for the multiview pca loss
  # [head_top,chin_base_top,chin1_4_top,chin_half_top,chin3_4_top,chin_tip_top,pectoral_L_base_top,pectoral_L_top,pectoral_R_base_top,pectoral_R_top,mid_top,dorsal_top,anal_top,tail_neck_top,fork_top,caudal_d_top,caudal_v_top,head_high,chin_base_high,chin1_4_high,chin_half_high,chin3_4_high,chin_tip_high,pectoral_L_base_high,pectoral_L_high,pectoral_R_base_high,pectoral_R_high,mid_high,dorsal_high,anal_high,tail_neck_high,fork_high,caudal_d_high,caudal_v_high,head_mid,chin_base_mid,chin1_4_mid,chin_half_mid,chin3_4_mid,chin_tip_mid,pectoral_L_base_mid,pectoral_L_mid,pectoral_R_base_mid,pectoral_R_mid,mid_mid,dorsal_mid,anal_mid,tail_neck_mid,fork_mid,caudal_d_mid,caudal_v_mid,head_low,chin_base_low,chin1_4_low,chin_half_low,chin3_4_low,chin_tip_low,pectoral_L_base_low,pectoral_L_low,pectoral_R_base_low,pectoral_R_low,mid_low,dorsal_low,anal_low,tail_neck_low,fork_low,caudal_d_low,caudal_v_low,led1_top,led2_top,led1_high,led2_high,led1_mid,led2_mid,led1_low,led2_low]
  mirrored_column_matches:
    - [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 68, 69]
    - [
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        70,
        71,
      ]
    - [
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        72,
        73,
      ]
    - [
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        74,
        75,
      ]
  columns_for_singleview_pca:
    [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19,
      20,
      21,
      22,
      23,
      24,
      25,
      26,
      27,
      28,
      29,
      30,
      31,
      32,
      33,
      34,
      35,
      36,
      37,
      38,
      39,
      40,
      41,
      42,
      43,
      44,
      45,
      46,
      47,
      48,
      49,
      50,
      51,
      52,
      53,
      54,
      55,
      56,
      57,
      58,
      59,
      60,
      61,
      62,
      63,
      64,
      65,
      66,
      67,
    ]

training:
  # select from one of several predefined image/video augmentation pipelines
  # default- resizing only
  # dlc- imgaug pipeline implemented in DLC 2.0 package
  # dlc-light- curated subset of dlc augmentations with more conservative param settings
  imgaug: dlc
  # batch size of labeled data during training
  train_batch_size: 4
  # batch size of labeled data during validation
  val_batch_size: 48
  # batch size of labeled data during test
  test_batch_size: 48
  # fraction of labeled data used for training
  train_prob: 0.8
  # fraction of labeled data used for validation (remaining used for test)
  val_prob: 0.1
  # <=1 - fraction of total train frames (determined by `train_prob`) used for training
  # >1 - number of total train frames used for training
  train_frames: 1
  # number of gpus to train a single model
  num_gpus: 1
  # number of cpu workers for data loaders
  num_workers: 4 # can do 8 for p3.2xlarge
  # epochs over which to assess validation metrics for early stopping
  early_stop_patience: 3
  # epoch at which backbone network weights begin updating
  unfreezing_epoch: 20
  # max training epochs; training may exit before due to early stopping
  min_epochs: 300
  max_epochs: 750
  # frequency to log training metrics (one step is one batch)
  log_every_n_steps: 5 # this dataset has fewer than 10 batches per epoch
  # frequency to log validation metrics
  check_val_every_n_epoch: 5
  # select gpu for training
  gpu_id: 0
  # rng seed for labeled batches
  rng_seed_data_pt: 0
  # rng seed for weight initialization
  rng_seed_model_pt: 0
  # learning rate scheduler
  # multisteplr | [todo - reducelronplateau]
  lr_scheduler: multisteplr
  lr_scheduler_params:
    multisteplr:
      milestones: [150, 200, 250]
      gamma: 0.5

model:
  # list of unsupervised losses
  # "pca_singleview" | "pca_multiview" | "temporal" | "unimodal_mse" | "unimodal_kl"
  losses_to_use: []
  # backbone network:
  # resnet18 | resnet34 | resnet50 | resnet101 | resnet152 | resnet50_contrastive
  # resnet50_animalpose_apose | resnet50_animal_ap10k
  # resnet50_human_jhmdb | resnet50_human_res_rle | resnet50_human_top_res
  # efficientnet_b0 | efficientnet_b1 | efficientnet_b2
  backbone: resnet50_animal_ap10k
  # prediction mode - "heatmap" | "regression"
  model_type: "heatmap"
  # which heatmap loss to use
  # "mse" | "kl" | "js"
  heatmap_loss_type: "mse"
  # tt expt name
  model_name: "biorxiv22a"
  # do context (5 frames)
  do_context: false

dali:
  general:
    seed: 123456
  base:
    train:
      sequence_length: 16 # 4 # step = sequence_length by default. done internally
    predict:
      # (train_batch_size + base.train.sequence_length) * 2 -> round down to nearest pow of 2
      # for fish_implant made it smaller to fit on g4dn.xlarge
      sequence_length: 32 # step = sequence_length by default. done internally.
  context:
    train: # defaults: sequence_length=5, step=sequence_length
      batch_size: 16
    predict: # defaults: sequence_length=5, step=1
      sequence_length: 32

losses:
  # loss = projection onto the discarded eigenvectors
  pca_multiview:
    # weight in front of PCA loss
    log_weight: 5.0
    # predictions whould lie within the low-d subspace spanned by these components
    components_to_keep: 3
    # percentile of reprojection errors on train data below which pca loss is zeroed out
    empirical_epsilon_percentile: 1.00
    # doing eff_epsilon = percentile(error, empirical_epsilon_percentile) * empirical_epsilon_multiplier
    empirical_epsilon_multiplier: 1.0
    # absolute error (in pixels) below which pca loss is zeroed out; if not null, this
    # parameter takes precedence over `empirical_epsilon_percentile`
    epsilon: null
  # loss = projection onto the discarded eigenvectors
  pca_singleview:
    # weight in front of PCA loss
    log_weight: 5.0
    # predictions whould lie within the low-d subspace spanned by components that describe this fraction of variance
    components_to_keep: 0.99
    # percentile of reprojection errors on train data below which pca loss is zeroed out
    empirical_epsilon_percentile: 1.00
    # doing eff_epsilon = percentile(error, empirical_epsilon_percentile) * empirical_epsilon_multiplier
    empirical_epsilon_multiplier: 1.0
    # absolute error (in pixels) below which pca loss is zeroed out; if not null, this
    # parameter takes precedence over `empirical_epsilon_percentile`
    epsilon: null
  # loss = norm of distance between successive timepoints
  temporal:
    # weight in front of temporal loss
    log_weight: 5.0
    # for epsilon insensitive rectification
    # (in pixels; diffs below this are not penalized)
    epsilon: 10.0
    # nan removal value.
    # (in prob; heatmaps with max prob values are removed)
    prob_threshold: 0.05

eval:
  # paths to the hydra config files in the output folder, OR absolute paths to such folders.
  hydra_paths: [" "]
  # predict?
  predict_vids_after_training: true
  # save .mp4?
  save_vids_after_training: false
  fiftyone:
    # will be the name of the dataset (Mongo DB) created by FiftyOne. for video dataset, we will append dataset_name + "_video"
    dataset_name: "implant-fish"
    build_speed: "slow" # "slow"/"fast". "fast" drops keypoint name and confidence information for faster processing.
    # if you want to manually provide a different model name to be displayed in FiftyOne
    model_display_names: ["test_model"]
    # whether to launch the app from the script (True), or from ipython (and have finer control over the outputs)
    launch_app_from_script: false

    remote: true # for LAI, must be False
    address: 127.0.0.1 # ip to launch the app on.
    port: 5151 # port to launch the app on.

    # whether to create a "videos" or "images" dataset, since the processes are the same
    dataset_to_create: "images"
  # str with an absolute path to a directory containing videos for prediction.
  # (it's not absolute just for the toy example)
  test_videos_directory: "/datastores/fish_implant/videos"
  # str with an absolute path to directory in which you want to save .csv with predictions
  saved_vid_preds_dir: "/home/jovyan"
  # confidence threshold for plotting a vid
  confidence_thresh_for_vid: 0.9
  # str with absolute path to the video file you want plotted with keypoints
  video_file_to_plot: ""
  # a list of strings, each points to a .csv file with predictions of a given model to the same video. will be combined with video_file_to_plot to make a visualization
  pred_csv_files_to_plot: [" "]

callbacks:
  anneal_weight:
    attr_name: "total_unsupervised_importance"
    init_val: 0.0
    increase_factor: 0.01
    final_val: 1.0
    freeze_until_epoch: 0
